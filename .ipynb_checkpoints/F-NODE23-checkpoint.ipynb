{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.4998 - accuracy: 0.8811\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2282 - accuracy: 0.9360\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1785 - accuracy: 0.9487\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1486 - accuracy: 0.9572\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1279 - accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1125 - accuracy: 0.9676\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1008 - accuracy: 0.9711\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0907 - accuracy: 0.9746\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0824 - accuracy: 0.9769\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0751 - accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c88397f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST데이터 로드\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 -2 Layer Perceptron\n",
    "model = keras.models.Sequential()\n",
    "# 입력층 d=784, 은닉층레이어 H=50\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))\n",
    "# 출력층 레이어 K=10\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.1011 - accuracy: 0.9681\n",
      "test_loss:0.10107238476648926\n",
      "test_accuracy:0.9681000113487244\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 결과\n",
    "# verbose2 :epoch당 1줄의 로그\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print('test_loss:{}'.format(test_loss))\n",
    "print('test_accuracy:{}'.format(test_accuracy))  #format의 다른활용 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameters/Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shpae)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "# 바이어스 파라미터 b를 생성하고 zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X,W1)+b1 # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25037035,  0.99607237, -0.88241222,  0.39543646,  1.01191845,\n",
       "       -0.13792064,  0.195563  , -0.92404164, -0.34318827,  0.29141884,\n",
       "        0.98159909,  1.67089526,  0.35913317, -0.98661716,  0.40519472,\n",
       "       -0.63136321, -0.16141909, -0.1717446 , -1.33916511,  1.57111586,\n",
       "        0.5040565 , -0.53763192,  0.07662242,  0.46082249,  1.05778741,\n",
       "       -0.37550594,  1.37737741,  1.46993102, -0.48363333,  0.04904029,\n",
       "        0.06277108,  0.92732853,  1.44976247, -1.02325466, -0.21709279,\n",
       "       -0.33043888, -0.33923657, -1.45466922,  0.69847378,  1.57419142,\n",
       "        0.25199016,  0.90689242, -1.1302023 , -0.04163388, -0.31171373,\n",
       "       -1.22905772,  0.54804233, -1.06952156,  0.95197816, -0.93668602])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 은닉층 출력 확인, 50dim?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마크다운 이미지 적용시 git/image폴더에 이동시킨후 상대경로 사용 (./image~~)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./image/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./image/relu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56226765 0.73028566 0.29267816 0.59759073 0.73339542 0.46557439\n",
      " 0.54873552 0.2841351  0.41503522 0.57234345 0.72742539 0.84169515\n",
      " 0.58883058 0.27158077 0.59993511 0.3472015  0.45973262 0.45716908\n",
      " 0.20764739 0.82794263 0.62341215 0.36873863 0.51914624 0.61320927\n",
      " 0.74226749 0.40721127 0.79856947 0.8130469  0.38139454 0.51225762\n",
      " 0.51568762 0.71653299 0.80996188 0.26439392 0.44593896 0.41813384\n",
      " 0.41599494 0.18928401 0.6678493  0.82838031 0.56266629 0.71236384\n",
      " 0.24412377 0.48959303 0.42269649 0.22634639 0.63368128 0.25549408\n",
      " 0.72151283 0.28157024]\n"
     ]
    }
   ],
   "source": [
    "# sigmoid함수 구현\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0]) #sigmoid : 0~1 사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W)+b\n",
    "    cache = (X, W ,b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30693519  0.64105596  0.62853352 -0.18883395 -0.19498565  0.29508387\n",
      " -0.585775    0.27363648 -0.69299099 -0.07941346]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "# z1이 다시 두번째 레이어의 입력이 됩니다\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "print(a2[0]) # 최종출력이 output_size만큼의 벡터가 되었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2에 softmax함수 적용 >> 입력X가 10가지 숫자중 하나일 확률\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T\n",
    "    \n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11900563, 0.16621656, 0.1641481 , 0.07248659, 0.07204205,\n",
       "       0.11760358, 0.04873808, 0.11510814, 0.04378295, 0.08086832])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "    \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t # 정답 라벨의 one-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11900563 0.16621656 0.1641481  0.07248659 0.07204205 0.11760358\n",
      " 0.04873808 0.11510814 0.04378295 0.08086832]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 최종출력 / 정답라벨의 one-hot인코딩 유사?\n",
    "print(y_hat[0]) # 4번째?\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_hat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.303327310160455"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]))/batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
