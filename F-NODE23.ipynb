{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4882 - accuracy: 0.8838\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2304 - accuracy: 0.9355\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1806 - accuracy: 0.9488\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1511 - accuracy: 0.9571\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1301 - accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1140 - accuracy: 0.9679\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1017 - accuracy: 0.9707\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0910 - accuracy: 0.9748\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0827 - accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0753 - accuracy: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f76e06641d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST데이터 로드\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 -2 Layer Perceptron\n",
    "model = keras.models.Sequential()\n",
    "# 입력층 d=784, 은닉층레이어 H=50\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))\n",
    "# 출력층 레이어 K=10\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.1057 - accuracy: 0.9684\n",
      "test_loss:0.10574383601546287\n",
      "test_accuracy:0.9684000015258789\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 결과\n",
    "# verbose2 :epoch당 1줄의 로그\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print('test_loss:{}'.format(test_loss))\n",
    "print('test_accuracy:{}'.format(test_accuracy))  #format의 다른활용 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameters/Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shpae)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "# 바이어스 파라미터 b를 생성하고 zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X,W1)+b1 # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81272192,  0.83720312,  0.6912861 ,  1.97685283, -1.35969143,\n",
       "        0.79202015, -1.12799159,  1.07994586,  0.59002358, -1.50673419,\n",
       "       -0.32320036, -0.34483249,  0.47264113, -1.6087786 ,  1.37154796,\n",
       "       -1.50698709,  0.81512538,  0.69900216,  0.25911332,  0.17149575,\n",
       "        0.28124712, -0.23745812,  0.21140337,  1.05975952,  0.62471259,\n",
       "       -0.82398951, -0.04209353, -0.49649966,  0.74979095, -1.54942319,\n",
       "        0.27250025,  1.05991942,  0.32207652, -1.67018723, -0.87219118,\n",
       "        0.16708357,  1.03428519,  1.14784554, -0.33923939, -1.55032302,\n",
       "        0.63125465,  0.84720165,  1.25918279, -0.97385966, -0.85991038,\n",
       "       -0.13940406, -0.00462667,  0.88392095, -0.72440927,  0.19350802])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 은닉층 출력 확인, 50dim?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69268923 0.69787583 0.66625296 0.87834527 0.20429046 0.68826493\n",
      " 0.24453194 0.74648374 0.64337056 0.18142329 0.41989599 0.41463609\n",
      " 0.61600869 0.16675826 0.79763013 0.18138574 0.69320061 0.6679665\n",
      " 0.56441831 0.54276917 0.56985195 0.44091285 0.55265489 0.74264459\n",
      " 0.65128959 0.30491746 0.48947817 0.37836361 0.67913315 0.17516959\n",
      " 0.56770661 0.74267515 0.57983023 0.15839922 0.29479857 0.54167399\n",
      " 0.73774583 0.75911718 0.41599425 0.17503962 0.6527739  0.6999798\n",
      " 0.7788854  0.27411186 0.29735807 0.46520532 0.49884333 0.70763408\n",
      " 0.32642277 0.54822661]\n"
     ]
    }
   ],
   "source": [
    "# sigmoid함수 구현\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0]) #sigmoid : 0~1 사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W)+b\n",
    "    cache = (X, W ,b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59348176 -0.56231345  0.05402467  0.17847506  0.12420465 -0.23307298\n",
      " -0.09269861 -0.15800525 -0.10208072 -0.38746711]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "# z1이 다시 두번째 레이어의 입력이 됩니다\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "print(a2[0]) # 최종출력이 output_size만큼의 벡터가 되었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2에 softmax함수 적용 >> 입력X가 10가지 숫자중 하나일 확률\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T\n",
    "    \n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06390138, 0.06592444, 0.12210085, 0.13828236, 0.13097773,\n",
       "       0.09162917, 0.1054381 , 0.09877232, 0.10445349, 0.07852017])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "    \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t # 정답 라벨의 one-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06390138 0.06592444 0.12210085 0.13828236 0.13097773 0.09162917\n",
      " 0.1054381  0.09877232 0.10445349 0.07852017]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 최종출력 / 정답라벨의 one-hot인코딩 유사?\n",
    "print(y_hat[0]) # 4번째?\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_hat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
